Conda uses environments to load different sets of Python packages
type conda env list to see the environments availible.
21/03/11 20:54:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/03/11 20:54:58 INFO SparkContext: Running Spark version 3.0.1
21/03/11 20:54:58 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
21/03/11 20:54:58 INFO ResourceUtils: ==============================================================
21/03/11 20:54:58 INFO ResourceUtils: Resources for spark.driver:

21/03/11 20:54:58 INFO ResourceUtils: ==============================================================
21/03/11 20:54:58 INFO SparkContext: Submitted application: COM6021_Assignment1_Question_2
21/03/11 20:54:58 INFO SecurityManager: Changing view acls to: lip20ps
21/03/11 20:54:58 INFO SecurityManager: Changing modify acls to: lip20ps
21/03/11 20:54:58 INFO SecurityManager: Changing view acls groups to: 
21/03/11 20:54:58 INFO SecurityManager: Changing modify acls groups to: 
21/03/11 20:54:58 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lip20ps); groups with view permissions: Set(); users  with modify permissions: Set(lip20ps); groups with modify permissions: Set()
21/03/11 20:54:59 INFO Utils: Successfully started service 'sparkDriver' on port 43851.
21/03/11 20:54:59 INFO SparkEnv: Registering MapOutputTracker
21/03/11 20:54:59 INFO SparkEnv: Registering BlockManagerMaster
21/03/11 20:54:59 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/11 20:54:59 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/11 20:54:59 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/03/11 20:54:59 INFO DiskBlockManager: Created local directory at /mnt/fastdata/lip20ps/blockmgr-647dbeba-780b-4080-b9a5-8b383fde0597
21/03/11 20:54:59 INFO MemoryStore: MemoryStore started with capacity 4.1 GiB
21/03/11 20:54:59 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/11 20:55:00 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/11 20:55:00 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://sharc-node002.shef.ac.uk:4040
21/03/11 20:55:00 INFO Executor: Starting executor ID driver on host sharc-node002.shef.ac.uk
21/03/11 20:55:00 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34695.
21/03/11 20:55:00 INFO NettyBlockTransferService: Server created on sharc-node002.shef.ac.uk:34695
21/03/11 20:55:00 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/11 20:55:01 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, sharc-node002.shef.ac.uk, 34695, None)
21/03/11 20:55:01 INFO BlockManagerMasterEndpoint: Registering block manager sharc-node002.shef.ac.uk:34695 with 4.1 GiB RAM, BlockManagerId(driver, sharc-node002.shef.ac.uk, 34695, None)
21/03/11 20:55:01 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, sharc-node002.shef.ac.uk, 34695, None)
21/03/11 20:55:01 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, sharc-node002.shef.ac.uk, 34695, None)
21/03/11 20:55:02 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/lip20ps/ScalableGIT/Assignment1/Code/spark-warehouse').
21/03/11 20:55:02 INFO SharedState: Warehouse path is 'file:/home/lip20ps/ScalableGIT/Assignment1/Code/spark-warehouse'.
21/03/11 21:01:38 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
21/03/11 21:01:38 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
21/03/11 21:01:41 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
21/03/11 21:01:41 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
(myspark) [lip20ps@sharc-node002 Code]$ spark-submit --driver-memory 8g Q2_Code-50-50.py
21/03/11 21:17:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/03/11 21:17:45 INFO SparkContext: Running Spark version 3.0.1
21/03/11 21:17:45 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
21/03/11 21:17:45 INFO ResourceUtils: ==============================================================
21/03/11 21:17:45 INFO ResourceUtils: Resources for spark.driver:

21/03/11 21:17:45 INFO ResourceUtils: ==============================================================
21/03/11 21:17:45 INFO SparkContext: Submitted application: COM6021_Assignment1_Question_2
21/03/11 21:17:45 INFO SecurityManager: Changing view acls to: lip20ps
21/03/11 21:17:45 INFO SecurityManager: Changing modify acls to: lip20ps
21/03/11 21:17:45 INFO SecurityManager: Changing view acls groups to: 
21/03/11 21:17:45 INFO SecurityManager: Changing modify acls groups to: 
21/03/11 21:17:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lip20ps); groups with view permissions: Set(); users  with modify permissions: Set(lip20ps); groups with modify permissions: Set()
21/03/11 21:17:46 INFO Utils: Successfully started service 'sparkDriver' on port 36573.
21/03/11 21:17:46 INFO SparkEnv: Registering MapOutputTracker
21/03/11 21:17:46 INFO SparkEnv: Registering BlockManagerMaster
21/03/11 21:17:46 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/11 21:17:46 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/11 21:17:46 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/03/11 21:17:46 INFO DiskBlockManager: Created local directory at /mnt/fastdata/lip20ps/blockmgr-e59294e1-661e-4dfa-aae6-d6aed70a2353
21/03/11 21:17:46 INFO MemoryStore: MemoryStore started with capacity 4.1 GiB
21/03/11 21:17:46 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/11 21:17:46 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/11 21:17:46 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://sharc-node002.shef.ac.uk:4040
21/03/11 21:17:47 INFO Executor: Starting executor ID driver on host sharc-node002.shef.ac.uk
21/03/11 21:17:47 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39427.
21/03/11 21:17:47 INFO NettyBlockTransferService: Server created on sharc-node002.shef.ac.uk:39427
21/03/11 21:17:47 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/11 21:17:47 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, sharc-node002.shef.ac.uk, 39427, None)
21/03/11 21:17:47 INFO BlockManagerMasterEndpoint: Registering block manager sharc-node002.shef.ac.uk:39427 with 4.1 GiB RAM, BlockManagerId(driver, sharc-node002.shef.ac.uk, 39427, None)
21/03/11 21:17:47 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, sharc-node002.shef.ac.uk, 39427, None)
21/03/11 21:17:47 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, sharc-node002.shef.ac.uk, 39427, None)
21/03/11 21:17:49 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/lip20ps/ScalableGIT/Assignment1/Code/spark-warehouse').
21/03/11 21:17:49 INFO SharedState: Warehouse path is 'file:/home/lip20ps/ScalableGIT/Assignment1/Code/spark-warehouse'.
Starting loading train data
+------+-------+------+---------+
|userId|movieId|rating|timestamp|
+------+-------+------+---------+
| 56769|   1176|   4.0|789652004|
|237556|     21|   3.0|789652009|
|237556|     47|   5.0|789652009|
|237556|   1079|   3.0|789652009|
|  5358|     19|   1.0|822873600|
| 26999|      2|   4.0|822873600|
| 26999|      7|   5.0|822873600|
| 26999|     10|   5.0|822873600|
| 26999|     11|   5.0|822873600|
| 26999|     12|   1.0|822873600|
+------+-------+------+---------+
only showing top 10 rows

Train data loaded
Starting loading test data
+------+-------+------+----------+
|userId|movieId|rating| timestamp|
+------+-------+------+----------+
| 82922| 167780|   4.0|1537945149|
| 82922|  53519|   4.0|1537945130|
|280481|    494|   3.0|1537945127|
|280481|   2355|   3.0|1537945123|
|280481|   2294|   2.0|1537945121|
|280481| 176101|   3.5|1537945110|
|280481|  64614|   3.0|1537945102|
| 82922| 165831|   4.0|1537945089|
|280481|   1079|   2.5|1537945086|
| 82922|  52281|   4.0|1537945085|
+------+-------+------+----------+
only showing top 10 rows

Train data loaded
21/03/11 21:24:39 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
21/03/11 21:24:39 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
21/03/11 21:24:41 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
21/03/11 21:24:41 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
Evaluation for 50/50 split
Root-mean-square error = 0.7904602910034219
Mean-square error = 0.6248274716532144
Mean-Absolute error = 0.6008922044578673
Root-mean-square error variation 1 = 0.7943050355350433
Mean-square error variation 1 = 0.6309204894763265
Mean-Absolute error variation 1 = 0.6008694768922234
Root-mean-square error variation 2 = 0.7943050355350434
Mean-square error variation 2 = 0.6309204894763265
Mean-Absolute error variation 2 = 0.6008694768922234
Clusters sizes are [6218, 5779, 9297, 7568, 7423, 10572, 6732, 7439, 6841, 8596, 4174, 5675, 9823, 16161, 4064, 5200, 11222, 8545, 2463, 6638]
Top 3 cluster with 50/50 split are 16161,11222 and 10572
Getting the list of all the user from largest cluster for 50 split
Converting it a python list - largestClusterUsers_50_list
Fetching for train data
Getting the movies id for all the users from largest cluster - Split 50
Converting it a python list - moviesforLargestCuster_50_list
Getting all the genres for the movies against the largest cluster - split 50
Converting it a python list - genres_largestCluster_list
Split the pipe '|' from the genres and adding them to list
Top 5 genres for 50-50 split for train data  ['Drama', 'Comedy', 'Romance', 'Thriller', 'Action']
Fetching for test data
Getting the movies id for all the users from largest cluster - Split 50
Converting it a python list - moviesforLargestCuster_50_list
Getting all the genres for the movies against the largest cluster - split 50
Converting it a python list - genres_largestCluster_list
Split the pipe '|' from the genres and adding them to list
Top 5 genres for 50-50 split for train data  ['Drama', 'Comedy', 'Thriller', 'Romance', 'Action']
Time take 1255.2371592521667
#####################################################
Clearing cache 
#####################################################
